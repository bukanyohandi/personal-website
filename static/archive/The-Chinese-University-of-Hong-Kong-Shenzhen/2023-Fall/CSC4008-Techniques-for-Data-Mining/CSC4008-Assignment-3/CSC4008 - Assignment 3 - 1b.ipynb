{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AWZ4Wbkg-p_",
        "outputId": "a42946de-1551-4161-cfdd-941b4e68be22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=49823da9f1d68bca6d87bcbcd166f4a3d4c85618679831f0eb2b1f4a4b298636\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark import SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, max as max_"
      ],
      "metadata": {
        "id": "uYzXcvMShDLs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf = SparkConf().setAppName(\"HITS\")\n",
        "sc = SparkContext.getOrCreate()"
      ],
      "metadata": {
        "id": "eOeMQNE6hElv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_edges = sc.textFile(\"drive/MyDrive/A3-data/graph-full.txt\")\n",
        "\n",
        "def parse_edge(edge):\n",
        "    nodes = edge.split(\"\\t\")\n",
        "    return (int(nodes[0]), int(nodes[1]))\n",
        "\n",
        "def parse_edge_2(edge):\n",
        "    nodes = edge.split(\"\\t\")\n",
        "    return (int(nodes[1]), int(nodes[0]))\n",
        "\n",
        "edges = input_edges.map(parse_edge).distinct()\n",
        "reversed_edges = input_edges.map(parse_edge_2).distinct()\n",
        "\n",
        "nodes = edges.flatMap(lambda x: (x[0], x[1])).distinct()\n",
        "\n",
        "edges = edges.groupByKey().cache()\n",
        "reversed_edges = reversed_edges.groupByKey().cache()\n",
        "\n",
        "hubs = nodes.map(lambda node: (node, 1.0))\n",
        "hubs_dict = hubs.collectAsMap()\n",
        "hubs_sc = sc.broadcast(hubs_dict)\n",
        "\n",
        "def compute_contribs(neighbors, rank):\n",
        "    for neighbor in neighbors:\n",
        "        yield (neighbor, rank)\n",
        "\n",
        "iterations = 40\n",
        "\n",
        "for iteration in range(iterations):\n",
        "    auths = edges.flatMap(\n",
        "        lambda edge_hub: compute_contribs(edge_hub[1], hubs_sc.value.get(edge_hub[0])\n",
        "    )).reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "    max_auth = auths.values().max()\n",
        "    auths = auths.mapValues(lambda rank: rank / max_auth)\n",
        "    auths_dict = auths.collectAsMap()\n",
        "    auths_sc = sc.broadcast(auths_dict)\n",
        "\n",
        "    hubs = reversed_edges.flatMap(\n",
        "        lambda auth_edge: compute_contribs(auth_edge[1], auths_sc.value.get(auth_edge[0]))\n",
        "    ).reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "    max_hub = hubs.values().max()\n",
        "    hubs = hubs.mapValues(lambda rank: rank / max_hub)\n",
        "    hubs_dict = hubs.collectAsMap()\n",
        "    hubs_sc = sc.broadcast(hubs_dict)\n",
        "\n",
        "hub_scores = hubs.collect()\n",
        "auth_scores = auths.collect()\n",
        "\n",
        "hub_scores.sort(key=lambda x: -x[1])\n",
        "auth_scores.sort(key=lambda x: -x[1])\n",
        "\n",
        "print(\"Top 5 nodes by hub score:\")\n",
        "for i in range(5):\n",
        "    print(hub_scores[i])\n",
        "\n",
        "print(\"Bottom 5 nodes by hub score:\")\n",
        "for i in range(1, 6):\n",
        "    print(hub_scores[-i])\n",
        "\n",
        "print(\"Top 5 nodes by authority score:\")\n",
        "for i in range(5):\n",
        "    print(auth_scores[i])\n",
        "\n",
        "print(\"Bottom 5 nodes by authority score:\")\n",
        "for i in range(1, 6):\n",
        "    print(auth_scores[-i])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afFnXKUchG_6",
        "outputId": "04dfa9fd-91c2-431b-b036-73b11cc5ea6c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 nodes by hub score:\n",
            "(840, 1.0)\n",
            "(155, 0.9499618624906541)\n",
            "(234, 0.8986645288972263)\n",
            "(389, 0.863417110184379)\n",
            "(472, 0.8632841092495217)\n",
            "Bottom 5 nodes by hub score:\n",
            "(23, 0.04206685489093653)\n",
            "(835, 0.05779059354433016)\n",
            "(141, 0.0645311764622518)\n",
            "(539, 0.06602659373418493)\n",
            "(889, 0.07678413939216454)\n",
            "Top 5 nodes by authority score:\n",
            "(893, 1.0)\n",
            "(16, 0.9635572849634397)\n",
            "(799, 0.9510158161074016)\n",
            "(146, 0.9246703586198443)\n",
            "(473, 0.8998661973604049)\n",
            "Bottom 5 nodes by authority score:\n",
            "(19, 0.05608316377607618)\n",
            "(135, 0.06653910487622794)\n",
            "(462, 0.075442286246419)\n",
            "(24, 0.08171239406816944)\n",
            "(910, 0.08571673456144875)\n"
          ]
        }
      ]
    }
  ]
}